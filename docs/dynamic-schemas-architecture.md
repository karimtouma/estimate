# Arquitectura de Esquemas Din√°micos
## Implementaci√≥n T√©cnica Detallada

---

## üèóÔ∏è **Arquitectura General**

### **Concepto Fundamental**
Los esquemas din√°micos resuelven la contradicci√≥n entre autonom√≠a y validaci√≥n:
- **Problema**: Taxonom√≠as fijas limitan la autonom√≠a
- **Soluci√≥n**: Esquemas que evolucionan en tiempo real bas√°ndose en el contenido descubierto

### **Componentes Core**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          DYNAMIC SCHEMA SYSTEM v2.0                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ DISCOVERY       ‚îÇ  ‚îÇ GEPA             ‚îÇ  ‚îÇ LANGUAGE    ‚îÇ  ‚îÇ REGISTRY     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ENGINE          ‚îÇ‚óÑ‚îÄ‚î§ OPTIMIZATION     ‚îÇ‚óÑ‚îÄ‚î§ ROUTER      ‚îÇ‚óÑ‚îÄ‚î§ MANAGER      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Strategic     ‚îÇ  ‚îÇ ‚Ä¢ Multi-Candidate‚îÇ  ‚îÇ ‚Ä¢ Auto      ‚îÇ  ‚îÇ ‚Ä¢ Auto-reg   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Sampling      ‚îÇ  ‚îÇ   Generation     ‚îÇ  ‚îÇ   Detection ‚îÇ  ‚îÇ ‚Ä¢ Evolution  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Pattern       ‚îÇ  ‚îÇ ‚Ä¢ Judge          ‚îÇ  ‚îÇ ‚Ä¢ Prompt    ‚îÇ  ‚îÇ ‚Ä¢ Validation ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Analysis      ‚îÇ  ‚îÇ   Evaluation     ‚îÇ  ‚îÇ   Optimization‚îÇ ‚îÇ ‚Ä¢ Persistence‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Nomenclature  ‚îÇ  ‚îÇ ‚Ä¢ Genetic        ‚îÇ  ‚îÇ ‚Ä¢ Multi-lang‚îÇ  ‚îÇ ‚Ä¢ Reliability‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Processing    ‚îÇ  ‚îÇ   Evolution      ‚îÇ  ‚îÇ   Support   ‚îÇ  ‚îÇ   Scoring    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Batch         ‚îÇ  ‚îÇ ‚Ä¢ Consensus      ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Optimization  ‚îÇ  ‚îÇ   Analysis       ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## GEPA Optimization System

### Funcionamiento T√©cnico

**GEPA (Genetic Evolution Prompt Architecture)** es el sistema de optimizaci√≥n que mejora continuamente la precisi√≥n de clasificaci√≥n mediante:

#### 1. Generaci√≥n de M√∫ltiples Candidatos
- **Candidatos por Elemento**: 5 opciones generadas por clasificaci√≥n
- **Diversidad de Enfoques**: Diferentes estrategias de prompting
- **API Integration**: Utiliza candidates nativos de Gemini API

#### 2. Sistema de Juez Inteligente
- **Criterios de Evaluaci√≥n**: Precisi√≥n, especificidad, relevancia del dominio, calibraci√≥n de confianza
- **Judge Score**: Promedio de 99.7% en evaluaci√≥n de calidad
- **Evaluaci√≥n Comparativa**: An√°lisis detallado de fortalezas y debilidades

#### 3. An√°lisis de Consenso
- **Agreement Level**: Nivel de acuerdo entre candidatos (promedio 97.5%)
- **Common Themes**: Identificaci√≥n de elementos comunes
- **Conflict Detection**: Detecci√≥n de √°reas de discrepancia para mejora

#### 4. Evoluci√≥n Gen√©tica
- **Population**: Conjunto de prompts de clasificaci√≥n
- **Fitness Function**: Basada en judge score y consenso
- **Genetic Operators**: Selecci√≥n, crossover, mutaci√≥n
- **Continuous Improvement**: Evoluci√≥n autom√°tica hacia mejor rendimiento

### M√©tricas GEPA

```json
{
  "gepa_statistics": {
    "total_enhancements": 6,
    "average_consensus": 0.975,
    "average_judge_score": 0.997,
    "average_improvement": 0.0008,
    "average_processing_time": 41.76,
    "confidence_distribution": {
      "high": 6, "medium": 0, "low": 0
    }
  }
}
```

---

## DynamicElementRegistry

### **Archivo**: `src/models/dynamic_schemas.py`

### **Responsabilidades**:
1. **Almacenamiento de tipos**: Mantiene registro de tipos descubiertos
2. **Evoluci√≥n de definiciones**: Mejora tipos con nueva evidencia
3. **Persistencia**: Guarda/carga registry entre sesiones
4. **M√©tricas**: Rastrea rendimiento y confiabilidad

### **Estructura de Datos**:
```python
@dataclass
class AdaptiveElementType:
    type_name: str
    base_category: CoreElementCategory
    specific_attributes: Dict[str, Any]
    discovery_confidence: float
    occurrence_count: int
    last_seen: float
    reliability_score: float
    evolution_history: List[Dict[str, Any]]
```

### **M√©todos Clave**:
- `register_discovered_type()` - Registra nuevos tipos
- `evolve_type_definition()` - Mejora definiciones existentes
- `get_type_definition()` - Recupera definiciones
- `calculate_reliability_score()` - Calcula confiabilidad

---

## üéØ **IntelligentTypeClassifier**

### **Archivo**: `src/models/intelligent_classifier.py`

### **Estrategias de Clasificaci√≥n** (En orden de prioridad):

#### **1. Registry Lookup** (O(1) - M√°s r√°pido)
```python
def _classify_by_registry_lookup(self, element_info, context):
    element_hash = self._generate_element_hash(element_info)
    existing_type = self.registry.get_type_by_hash(element_hash)
    if existing_type:
        return ClassificationResult(
            classified_type=existing_type.type_name,
            confidence=existing_type.reliability_score,
            discovery_method=DiscoveryMethod.REGISTRY_LOOKUP
        )
```

#### **2. Pattern Matching** (Heur√≠stico - Eficiente)
```python
def _classify_by_pattern_matching(self, element_info, context):
    visual_features = element_info.get('visual_features', {})
    text_features = element_info.get('textual_features', {})
    
    # An√°lisis de patrones visuales y textuales
    for pattern in self.known_patterns:
        if self._matches_pattern(visual_features, text_features, pattern):
            return ClassificationResult(...)
```

#### **3. Nomenclature Analysis** (Contextual)
```python
def _classify_by_nomenclature_analysis(self, element_info, context):
    text_content = element_info.get('text_content', '')
    codes = self._extract_nomenclature_codes(text_content)
    
    for code in codes:
        type_hint = self._analyze_nomenclature_code(code)
        if type_hint and confidence >= 0.6:
            return ClassificationResult(...)
```

#### **4. AI Reasoning** (M√°s inteligente - Gemini)
```python
async def _classify_by_ai_reasoning(self, element_info, context):
    prompt = self._create_ai_classification_prompt(element_info, context)
    
    response_text = self.gemini_client.generate_text_only_content(
        prompt=prompt,
        response_schema=self._get_classification_schema()
    )
    
    ai_result = self._parse_ai_classification_response(response_text)
    return ClassificationResult(...)
```

### **Auto-Registro de Tipos**:
```python
def _auto_register_type(self, classification_result, element_info):
    if classification_result.confidence >= self.auto_register_threshold:
        self.registry.register_discovered_type(
            type_name=classification_result.classified_type,
            category=classification_result.base_category,
            confidence=classification_result.confidence,
            evidence=element_info
        )
```

---

## üîç **Sistema de Descubrimiento**

### **DynamicPlanoDiscovery** (`src/discovery/dynamic_discovery.py`)

#### **Muestreo Estrat√©gico**:
```python
def strategic_sampling(self, total_pages: int, sample_size: int = 10):
    if total_pages <= 15:
        # Documentos peque√±os: analizar todas las p√°ginas
        return list(range(total_pages))
    
    # Documentos grandes: muestreo inteligente
    coverage_percentage = min(30, max(20, 100 * sample_size / total_pages))
    
    # P√°ginas cr√≠ticas siempre incluidas
    critical_pages = [0, total_pages//2, total_pages-1]
    
    # Muestreo distribuido del resto
    remaining_sample = sample_size - len(critical_pages)
    distributed_pages = self._distribute_sampling(remaining_sample, total_pages)
    
    return sorted(set(critical_pages + distributed_pages))
```

#### **Cach√© Inteligente**:
```python
def _initialize_smart_cache(self):
    # Pre-cargar p√°ginas cr√≠ticas para acceso instant√°neo
    critical_pages = [0, min(2, self.total_pages-1), self.total_pages-1]
    
    for page_num in critical_pages:
        page_text = self.pdf_document[page_num].get_text()
        self.page_cache[page_num] = {
            'text': page_text,
            'complexity': self._calculate_visual_complexity(page_num),
            'cached_at': time.time()
        }
```

### **EnhancedDynamicDiscovery** (`src/discovery/enhanced_discovery.py`)

#### **Integraci√≥n con Clasificador**:
```python
async def _enhance_discovery_with_dynamic_schemas(self, base_discovery):
    unique_elements = self._extract_unique_elements_from_discovery(base_discovery)
    
    classified_elements = []
    for element in unique_elements:
        classification = await self.intelligent_classifier.classify_element(
            element_data=element,
            context={'document_type': base_discovery.document_type}
        )
        classified_elements.append(classification)
    
    return EnhancedDiscoveryResult(
        discovered_element_types=classified_elements,
        auto_registered_types=self._get_auto_registered_types(),
        registry_stats=self.dynamic_registry.get_statistics()
    )
```

---

## ‚öôÔ∏è **Configuraci√≥n del Sistema**

### **Archivo**: `config.toml`

#### **Configuraci√≥n de An√°lisis**:
```toml
[analysis]
enable_dynamic_schemas = true
enabled_types = ["general", "sections", "data_extraction"]

# Umbrales de clasificaci√≥n
auto_register_confidence_threshold = 0.85
validation_threshold = 0.7
new_discovery_threshold = 0.6

# Preguntas por defecto (se generan adaptativas si no se especifican)
default_questions = [
    "¬øQu√© tipo de estructura se muestra en este documento?",
    "¬øCu√°l es el alcance y prop√≥sito de este documento?",
    # ... m√°s preguntas ...
]
```

#### **Configuraci√≥n de API**:
```toml
[api]
gemini_api_key = "${GEMINI_API_KEY}"
default_model = "gemini-2.5-pro"
max_concurrent_requests = 3
temperature = 0.3
top_p = 0.8
top_k = 40
max_output_tokens = 8192
```

---

## üìä **Flujo de Datos**

### **Proceso Completo**:

```mermaid
sequenceDiagram
    participant U as Usuario
    participant CLI as CLI
    participant AP as AdaptiveProcessor
    participant DD as DynamicDiscovery
    participant IC as IntelligentClassifier
    participant GC as GeminiClient
    participant DR as DynamicRegistry

    U->>CLI: make job
    CLI->>AP: comprehensive_analysis_adaptive()
    AP->>GC: upload_pdf()
    GC-->>AP: file_uri
    
    AP->>DD: enhanced_initial_exploration()
    DD->>GC: analyze_batch_discovery()
    GC-->>DD: discovery_result
    DD->>IC: classify_element()
    IC->>GC: generate_text_only_content()
    GC-->>IC: classification
    IC->>DR: register_discovered_type()
    DR-->>IC: type_registered
    IC-->>DD: classified_elements
    DD-->>AP: enhanced_discovery_result
    
    AP->>AP: analyze_document() x3
    AP->>GC: multi_turn_analysis()
    GC-->>AP: qa_results
    
    AP->>DD: create_complete_page_map()
    DD->>GC: classify_page_batch() x11
    GC-->>DD: page_classifications
    DD-->>AP: page_map
    
    AP-->>CLI: comprehensive_result
    CLI-->>U: analysis_complete
```

---

## üîß **Implementaci√≥n de Esquemas**

### **Schema JSON para Gemini**:
```json
{
  "type": "object",
  "properties": {
    "type_name": {
      "type": "string",
      "description": "Nombre espec√≠fico del tipo de elemento"
    },
    "category": {
      "type": "string",
      "enum": ["structural", "architectural", "mep", "annotation", "specialized"],
      "description": "Categor√≠a base del elemento"
    },
    "confidence": {
      "type": "number",
      "minimum": 0.0,
      "maximum": 1.0,
      "description": "Nivel de confianza de la clasificaci√≥n"
    },
    "reasoning": {
      "type": "string",
      "description": "Explicaci√≥n del razonamiento de clasificaci√≥n"
    },
    "domain_context": {
      "type": "string",
      "description": "Contexto del dominio (residencial, comercial, etc.)"
    },
    "industry_context": {
      "type": "string", 
      "description": "Contexto de la industria (construcci√≥n, etc.)"
    }
  },
  "required": ["type_name", "category", "confidence"]
}
```

### **Validaci√≥n Pydantic**:
```python
class ComprehensiveAnalysisResult(BaseModel):
    file_info: dict = Field(description="Informaci√≥n del archivo procesado")
    general_analysis: Optional[DocumentAnalysis] = None
    sections_analysis: Optional[List[SectionAnalysis]] = None
    data_extraction: Optional[DataExtraction] = None
    qa_analysis: Optional[List[QuestionAnswer]] = None
    discovery_analysis: Optional[dict] = Field(default=None)
    dynamic_schema_results: Optional[dict] = Field(default=None)  # ‚Üê CLAVE
    page_map: Optional[DocumentPageMap] = Field(default=None)
    metadata: Optional[ProcessingMetadata] = None
```

---

## üéØ **Casos de Uso Verificados**

### **Documento Analizado**: Canyon Del Rio Clubhouse
- **P√°ginas**: 51
- **Tipo**: Planos de construcci√≥n AEC
- **Tiempo**: 6.5-9.2 minutos
- **Costo**: $0.07 USD
- **√âxito**: 100%

### **Tipos Descubiertos Autom√°ticamente**:
1. `general_note` (annotation, 0.95)
2. `sheet_reference_note` (annotation, 0.95)
3. `cross_reference_note` (annotation, 0.98)
4. `drawing_title` (annotation, 0.95)
5. `view_title` (annotation, 0.95)
6. `accessibility_specification` (specialized, 0.95)

### **M√©tricas de Autonom√≠a**:
- **Discovery Rate**: 83-100%
- **Auto-Registration**: 5-6 tipos por documento
- **Classification Confidence**: 0.95-0.98
- **Schema Evolution**: Autom√°tica

---

## üî¨ **Detalles de Implementaci√≥n**

### **Generaci√≥n de Hash para Elementos**:
```python
def _generate_element_hash(self, element_info: Dict[str, Any]) -> str:
    # Combina caracter√≠sticas visuales y textuales
    visual_hash = hashlib.md5(str(element_info.get('visual_features', {})).encode()).hexdigest()[:8]
    text_hash = hashlib.md5(element_info.get('text_content', '').encode()).hexdigest()[:8]
    return f"{visual_hash}_{text_hash}"
```

### **C√°lculo de Confianza**:
```python
def _calculate_confidence(self, evidence: Dict[str, Any]) -> float:
    base_confidence = evidence.get('ai_confidence', 0.5)
    
    # Factores de ajuste
    text_clarity = self._assess_text_clarity(evidence.get('text_content', ''))
    visual_clarity = self._assess_visual_clarity(evidence.get('visual_features', {}))
    context_support = self._assess_context_support(evidence.get('context', {}))
    
    # F√≥rmula de confianza ponderada
    final_confidence = (
        base_confidence * 0.4 +
        text_clarity * 0.3 +
        visual_clarity * 0.2 +
        context_support * 0.1
    )
    
    return min(1.0, max(0.0, final_confidence))
```

### **Evoluci√≥n de Tipos**:
```python
def evolve_type_definition(self, type_name: str, new_evidence: Dict[str, Any]):
    existing_def = self.types[type_name]
    
    # Merge evidencia nueva con existente
    merged_attributes = self._merge_attributes(
        existing_def.specific_attributes,
        new_evidence
    )
    
    # Recalcular confiabilidad
    new_reliability = self._calculate_updated_reliability(
        existing_def,
        new_evidence
    )
    
    # Actualizar definici√≥n
    existing_def.specific_attributes = merged_attributes
    existing_def.reliability_score = new_reliability
    existing_def.evolution_history.append({
        'timestamp': time.time(),
        'evidence': new_evidence,
        'reliability_change': new_reliability - existing_def.reliability_score
    })
```

---

## üìà **M√©tricas y Monitoreo**

### **M√©tricas de Rendimiento**:
```python
class ClassificationPerformance:
    total_classifications: int
    discoveries_made: int
    discovery_rate: float
    average_accuracy: float
    registry_size: int
    
    def calculate_discovery_rate(self):
        return self.discoveries_made / max(1, self.total_classifications)
```

### **Estad√≠sticas del Registry**:
```python
def get_statistics(self) -> Dict[str, Any]:
    return {
        "total_types": len(self.types),
        "category_counts": self._count_by_category(),
        "most_reliable_types": self._get_most_reliable_types(limit=5),
        "recent_discoveries": self._get_recent_discoveries(limit=5),
        "total_discoveries": self.total_discoveries,
        "created_timestamp": self.created_timestamp,
        "last_updated_timestamp": self.last_updated_timestamp
    }
```

---

## üõ°Ô∏è **Tolerancia a Fallos**

### **Manejo de Errores en Clasificaci√≥n**:
```python
async def classify_element(self, element_data, context=None):
    for strategy in self.strategies:
        try:
            result = await strategy(element_data, context)
            if result and result.confidence >= self.validation_threshold:
                return result
        except Exception as e:
            logger.warning(f"Strategy {strategy.__name__} failed: {e}")
            continue
    
    # Fallback a clasificaci√≥n b√°sica
    return self._fallback_classification(element_data)
```

### **Validaci√≥n de Respuestas AI**:
```python
def _parse_ai_classification_response(self, response_text: str):
    try:
        # Extraer JSON de la respuesta
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
            
            # Validar campos requeridos
            required_fields = ['type_name', 'category', 'confidence']
            if all(field in data for field in required_fields):
                return data
                
    except (json.JSONDecodeError, AttributeError) as e:
        logger.warning(f"Failed to parse AI response: {e}")
    
    return None
```

---

## üéØ **Optimizaciones Futuras**

### **Persistencia de Registry**:
- Guardar tipos descubiertos entre sesiones
- Cargar registry existente al inicializar
- Backup autom√°tico de registry

### **Aprendizaje Incremental**:
- Mejora continua con m√°s documentos
- Transferencia de conocimiento entre dominios
- Optimizaci√≥n de estrategias de clasificaci√≥n

### **M√©tricas Avanzadas**:
- Dashboard de rendimiento en tiempo real
- An√°lisis de tendencias de descubrimiento
- Alertas de degradaci√≥n de rendimiento

---

*Documentaci√≥n t√©cnica generada para PDF Estimator v2.0.0*
*Septiembre 2025*
